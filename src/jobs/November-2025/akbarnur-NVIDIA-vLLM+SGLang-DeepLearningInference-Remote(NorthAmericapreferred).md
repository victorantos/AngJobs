---
title: "NVIDIA : vLLM + SGLang"
author:
  name: akbarnur
  url: https://news.ycombinator.com/item?id=45806560
---
NVIDIA - vLLM + SGLang - Deep Learning Inference - Remote (North America preferred)

Hi everyone — I’m Akbar, Senior Manager of Deep Learning Inference Software at NVIDIA. I lead our engineering efforts around vLLM and SGLang, two of the most widely used open-source LLM inference frameworks.

We’re building teams focused on making LLM inference faster, more efficient, and more reliable at scale — from runtime and scheduling optimizations to kernel fusion, distributed serving, and continuous integration across new GPU architectures (Hopper, Blackwell, etc.).

We’re hiring for multiple roles:

• Senior Deep Learning Software Engineer, Inference (<a href="https:&#x2F;&#x2F;nvidia.wd5.myworkdayjobs.com&#x2F;NVIDIAExternalCareerSite&#x2F;job&#x2F;US-CA-Santa-Clara&#x2F;Senior-Deep-Learning-Software-Engineer--Inference_JR2003655" rel="nofollow">https:&#x2F;&#x2F;nvidia.wd5.myworkdayjobs.com&#x2F;NVIDIAExternalCareerSit...</a>)

• Engineering Manager, Deep Learning Inference (<a href="https:&#x2F;&#x2F;nvidia.wd5.myworkdayjobs.com&#x2F;NVIDIAExternalCareerSite&#x2F;job&#x2F;US-CA-Santa-Clara&#x2F;Engineering-Manager--Deep-Learning-Inference_JR2006335" rel="nofollow">https:&#x2F;&#x2F;nvidia.wd5.myworkdayjobs.com&#x2F;NVIDIAExternalCareerSit...</a>)

• DL Performance Software Engineer - LLM Inference (<a href="https:&#x2F;&#x2F;nvidia.wd5.myworkdayjobs.com&#x2F;en-US&#x2F;NVIDIAExternalCareerSite&#x2F;job&#x2F;DL-Performance-Software-Engineer---LLM-Inference_JR2002786-1" rel="nofollow">https:&#x2F;&#x2F;nvidia.wd5.myworkdayjobs.com&#x2F;en-US&#x2F;NVIDIAExternalCar...</a>)

• DL Performance Software Engineer - LLM Inference (<a href="https:&#x2F;&#x2F;nvidia.wd5.myworkdayjobs.com&#x2F;en-US&#x2F;NVIDIAExternalCareerSite&#x2F;job&#x2F;DL-Performance-Software-Engineer---LLM-Inference_JR2004804" rel="nofollow">https:&#x2F;&#x2F;nvidia.wd5.myworkdayjobs.com&#x2F;en-US&#x2F;NVIDIAExternalCar...</a>)

These roles are remote-friendly (North America preferred) and fully focused on upstream open-source development — working directly with the maintainers and the wider AI community.

If you’re excited about large-scale inference, compiler&#x2F;runtime performance, and pushing GPUs to their limits, we’d love to talk.
<JobApplication />
